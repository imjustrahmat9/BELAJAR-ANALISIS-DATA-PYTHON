# -*- coding: utf-8 -*-
"""Rahmat Hidayat_Projek Analisis Data Python

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NTPBmr_0oPwkn4t67uuYo2K8b7U4eOwI

# Proyek Analisis Data: [E-Commerce Public Dataset]

- Nama: Rahmat Hidayat
- Email: mc013d5y1559@student.devacademy.id
- ID Dicoding: MC013D5Y1559

## Menentukan Pertanyaan Bisnis

1.   Produk mana yang memiliki penjualan tertinggi dan terendah?
2.   Berapa total pendapatan yang diperoleh dalam enam bulan terakhir dan selama seluruh periode?

## Import Semua Packages/Library yang Digunakan
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""## Data Wrangling

### Gathering data

**1. Memuat tabel orders**
"""

orders_df = pd.read_csv("/content/drive/MyDrive/Analisis Data Python/orders_dataset.csv")
orders_df.head()

from google.colab import drive
drive.mount('/content/drive')

"""**Insight :**
- **orders_dataset:**

a. Distribusi Penjual: Mengevaluasi sebaran geografis penjual serta peran mereka dalam total penjualan.

b. Kinerja Penjual: Menganalisis performa penjual berdasarkan volume penjualan dan ulasan pelanggan.

**2. Memuat tabel produk**
"""

produk_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_products_dataset.csv")
produk_df.head()

"""**Insight :**
- **products_dataset:**
  - Menentukan kategori produk dengan tingkat popularitas tertinggi dan terendah.

**3. Memuat tabel seller**
"""

seller_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_sellers_dataset.csv")
seller_df.head()

"""**Insight :**
- **sellers_dataset:**

a. Distribusi Penjual: Menganalisis sebaran geografis penjual serta kontribusi mereka terhadap total penjualan.

b. Kinerja Penjual: Mengevaluasi performa penjual berdasarkan jumlah penjualan dan ulasan pelanggan.

**4. Memuat tabel kategori_produk**
"""

kategori_produk_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/product_category_name_translation.csv")
kategori_produk_df.head()

"""**Insight :**
- **product_category_name_translation_dataset :**
  - Kategori Produk: Menghubungkan nama kategori produk dalam bahasa asli dengan terjemahannya untuk analisis lebih lanjut.
  - Analisis Kategori: Mengidentifikasi kategori produk yang paling banyak terjual dan kontribusi mereka terhadap pendapatan total.

**5. Memuat tabel order_item**
"""

order_item_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_order_items_dataset.csv")
order_item_df.head()

"""**Insight :**
- **order_items_dataset:**
  - Produk Terlaris: Mengidentifikasi produk yang paling banyak terjual dan kontribusi mereka terhadap pendapatan total.
  - Kinerja Penjual: Menilai performa penjual berdasarkan jumlah penjualan dan ulasan pelanggan.

**6. Memuat tabel payment**
"""

payment_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_order_payments_dataset.csv")
payment_df.head()

"""**Insight :**
- **payments_dataset:**
  - Metode Pembayaran: Menilai metode pembayaran yang paling sering digunakan oleh pelanggan.
  - Nilai Transaksi: Menganalisis nilai transaksi rata-rata dan total untuk memahami perilaku pembelian pelanggan.

**7. Memuat tabel review**
"""

review_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_order_reviews_dataset.csv")
review_df.head()

"""**Insight :**
- **reviews_dataset:**
  - Kepuasan Pelanggan: Menilai ulasan pelanggan untuk memahami tingkat kepuasan.

**8. Memuat tabel geolokasi**
"""

geolokasi_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_geolocation_dataset.csv")
geolokasi_df.head()

"""**Insight :**
- **geolocation_dataset :**
  - Lokasi Pengiriman: Menghubungkan kode pos dengan koordinat geografis untuk analisis lebih lanjut tentang waktu dan biaya pengiriman.

**9. Memuat tabel customer**
"""

customer_df = pd.read_csv("C:/Users/USER/Project_Python/Dicoding/proyek_analisis_data/E-Commerce Public Dataset/olist_customers_dataset.csv")
customer_df.head()

"""**Insight :**
- **customers_dataset:**
  - Distribusi Pelanggan: Menilai distribusi geografis pelanggan berdasarkan kota dan negara    bagian. Ini dapat membantu dalam memahami area dengan permintaan tertinggi dan terendah.
  - Pelanggan Unik: Mengidentifikasi pelanggan yang melakukan pembelian berulang di toko.

### Assessing data

**1. Menilai data orders_df**

**1.1. memeriksa tipe data dan missing value**
"""

orders_df.info()

"""**Insight :**

- Terdapat kesalahan tipe data di kolom :

      - order_purchase_timestamp
      - order_approved_at
      - order_delivered_carrier_date
      - order_delivered_customer_date
      - order_estimated_delivery_date.
  
  kolom-kolom tersebut harusnya direpresentasikan sebagai tipe data datetime.
  
- Terdapat juga sedikit perbedaan pada jumlah data pada kolom :
  
      - order_approved_at   
      - order_delivered_carrier_date
      - order_delivered_customer_date.
  
  Hal ini menunjukkan adanya missing values pada kedua kolom tersebut.

**1.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

orders_df.isna().sum()

"""**Insight :**

terdapat jumlah missing value yang cukup banyak. untuk menganalisa lebih lanjut, kita dapat memeriksa lebih lanjut melalui kolom order_status

**1.3. memeriksa duplikasi data**
"""

print("Jumlah duplikasi: ",orders_df.duplicated().sum())

"""**Insight :**

Ini menunjukkan tidak terdapat duplikasi pada orders_df.

**1.4. memeriksa parameter statistik dari kolom numerik**
"""

orders_df.describe()

"""**Insight :**

Ini menunjukkan tidak terdapat keanehan nilai pada orders_df.

**2. Menilai data produk_df**

**2.1. memeriksa tipe data dan missing value**
"""

produk_df.info()

"""**Insight :**

- Terdapat missing values pada hampir semua kolom kecuali kolom product_id.

**2.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

produk_df.isna().sum()

"""**Insight :**

terdapat jumlah missing value yang cukup banyak pada sebagian kolom. untuk menganalisa lebih lanjut, kita dapat memeriksa melalui kolom product_category_name.

**2.3. memeriksa duplikasi data**
"""

print("Jumlah duplikasi: ",produk_df.duplicated().sum())

"""**Insight :**

Ini menunjukkan tidak terdapat duplikasi data pada produk_df.

**2.4. memeriksa parameter statistik dari kolom numerik**
"""

produk_df.describe()

"""**Insight :**

Ini menunjukkan tidak terdapat keanehan nilai pada produk_df.

**3. Menilai data seller_df**

**3.1. memeriksa tipe data dan missing value**
"""

seller_df.info()

"""**Insight :**

Ini menunjukkan tidak terdapat kesalahan tipe data maupun missing value pada seller_df.

**3.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

seller_df.isna().sum()

"""**3.3. memeriksa duplikasi data**"""

print("Jumlah duplikasi: ",seller_df.duplicated().sum())

"""**Insight :**

Ini menunjukkan tidak terdapat duplikasi data pada seller_df.

**3.4. memeriksa parameter statistik dari kolom numerik**
"""

seller_df.describe()

"""**Insight :**

Ini menunjukkan tidak terdapat keanehan nilai pada seller_df.

**4. Menilai data kategori_produk_df**

**4.1. memeriksa tipe data dan missing value**
"""

kategori_produk_df.info()

"""**Insight :**

Ini menunjukkan tidak terdapat kesalahan tipe data maupun missing value pada kategori_produk_df.

**4.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

kategori_produk_df.isna().sum()

"""**4.3. memeriksa duplikasi data**"""

print("Jumlah duplikasi: ",kategori_produk_df.duplicated().sum())

"""**Insight :**

Ini menunjukkan tidak terdapat duplikasi data pada kategori_produk_df.

**4.4. memeriksa parameter statistik dari kolom numerik**
"""

kategori_produk_df.describe()

"""**Insight :**

Ini menunjukkan tidak terdapat keanehan nilai pada kategori_produk_df.

**5. Menilai data order_item_df**

**5.1. memeriksa tipe data dan missing value**
"""

order_item_df.info()

"""**Insight :**

- Terdapat kesalahan tipe data di kolom shipping_limit_date, kolom tersebut harusnya direpresentasikan sebagai tipe data datetime.
- Tidak terdapat missing value pada data payment_df

**5.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

order_item_df.isna().sum()

"""**5.3. menampilkan duplikasi data**"""

print("Jumlah duplikasi: ",order_item_df.duplicated().sum())

"""**Insight :**

Tidak terdapat duplikasi data pada order_item_df.

**5.4. memeriksa parameter statistik dari kolom numerik**
"""

order_item_df.describe()

"""**Insight :**

Tidak terdapat keanehan nilai pada order_item_df.

**6. Menilai data payment_df**

**6.1. memeriksa tipe data dan missing value**
"""

payment_df.info()

"""**Insight :**

- Tidak terdapat kesalahan tipe data.
- Tidak terdapat missing value pada data payment_df

**6.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

payment_df.isna().sum()

"""**6.3. menampilkan duplikasi data**"""

print("Jumlah duplikasi: ",payment_df.duplicated().sum())

"""**Insight :**

Tidak terdapat duplikasi data pada payment_df.

**6.4. memeriksa parameter statistik dari kolom numerik**
"""

payment_df.describe()

"""**Insight :**

Tidak terdapat keanehan nilai pada payment_df.

**7. Menilai data review_df**

**7.1. memeriksa tipe data dan missing value**
"""

review_df.info()

"""**Insight :**

- Terdapat kesalahan tipe data pada kolom :
    - review_creation_date
    - review_answer_timestamp

- Terdapat missing value pada kolom :
    - review_comment_title
    - review_comment_message

**7.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

review_df.isna().sum()

"""**Insight :**

terdapat jumlah missing value yang cukup banyak pada kolom review_comment_title dan review_comment_message. untuk menganalisa lebih lanjut, kita dapat memeriksa melalui kolom review_score.

**7.3. menampilkan duplikasi data**
"""

print("Jumlah duplikasi: ",review_df.duplicated().sum())

"""**Insight :**

Tidak terdapat duplikasi data pada review_df.

**7.4. memeriksa parameter statistik dari kolom numerik**
"""

review_df.describe()

"""**Insight :**

Tidak terdapat keanehan nilai pada review_df.

**8. Menilai data geolokasi_df**

**8.1. memeriksa tipe data dan missing value**
"""

geolokasi_df.info()

"""**Insight :**

- Tidak terdapat kesalahan tipe data.
- Tidak terdapat missing value.

**8.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

geolokasi_df.isna().sum()

"""**8.3. menampilkan duplikasi data**"""

print("Jumlah duplikasi: ",geolokasi_df.duplicated().sum())

"""**Insight :**

terdapat duplikasi data yang cukup banyak, akan dibersihkan pada tahap cleansing data.

**8.4. memeriksa parameter statistik dari kolom numerik**
"""

geolokasi_df.describe()

"""**Insight :**

Tidak terdapat keanehan nilai pada geolokasi_df.

**9. Menilai data customer_df**

**9.1. memeriksa tipe data dan missing value**
"""

customer_df.info()

"""**Insight :**

- Tidak terdapat kesalahan tipe data.
- Tidak terdapat missing value.

**9.2. menampilkan informasi terkait jumlah missing values yang terdapat dalam setiap kolom**
"""

customer_df.isna().sum()

"""**9.3. menampilkan duplikasi data**"""

print("Jumlah duplikasi: ",customer_df.duplicated().sum())

"""**Insight :**

Tidak terdapat duplikasi data pada customer_df.

**9.4. memeriksa parameter statistik dari kolom numerik**
"""

customer_df.describe()

"""**Insight :**

Tidak terdapat keanehan nilai pada customer_df.

**Berikut rangkumannya pada tahap assessing data :**
1. orders_df
    - Tipe data :
      - order_purchase_timestamp
      - order_approved_at
      - order_delivered_carrier_date
      - order_delivered_customer_date
      - order_estimated_delivery_date.
    - Missing value :
      - order_approved_at = 160
      - order_delivered_carrier_date = 1783
      - order_delivered_customer_date = 2965
    - Duplikat data : -
    - Inaccurate value : -
2. produk_df
    - Tipe data : -
    - Missing value :
      - product_category_name         = 610
      - product_name_lenght           = 610
      - product_description_lenght    = 610
      - product_photos_qty            = 610
      - product_weight_g              = 2
      - product_length_cm             = 2  
      - product_height_cm             = 2  
      - product_width_cm              = 2
    - Duplikat data : -
    - Inaccurate value : -
3. seller_df
    - Tipe data : -
    - Missing Value : -
    - Duplikat data : -
    - Inaccurate value : -
4. kategori_produk_df
    - Tipe data : -
    - Missing Value : -
    - Duplikat data : -
    - Inaccurate value : -
5. order_item_df
    - Tipe data :
        - shipping_limit_date
    - Missing value : -
    - Duplikat data : -
    - Inaccurate value : -
6. payment_df
    - Tipe data : -
    - Missing Value : -
    - Duplikat data : -
    - Inaccurate value : -
7. review_df
    - Tipe data :
       - review_creation_date  
       - review_answer_timestamp
    - Missing value :
       - review_comment_title   
       - review_comment_message
    - Duplikat data : -
    - Inaccurate value : -
8. geolokasi_df
    - Tipe data : -
    - Missing value : -
    - Duplikat data : 261831
    - Inaccurate value : -
9. customer_df
    - Tipe data : -
    - Missing Value : -
    - Duplikat data : -
    - Inaccurate value : -

### Cleaning data

**1. Membersihkan data orders_df**

Berdasarkan hasil proses assessing data, diketahui bahwa terdapat dua masalah yang dijumpai dalam orders_df, yaitu tipe data, dan missing value.

**1.1. Menangani tipe data**
"""

datetime_columns = ["order_purchase_timestamp", "order_approved_at", "order_delivered_carrier_date", "order_delivered_customer_date", "order_estimated_delivery_date"]

for column in datetime_columns:
  orders_df[column] = pd.to_datetime(orders_df[column])

"""**1.2. Menangani missing value**

Kita bisa memfilter satu persatu dari ketiga kolom untuk dianalisa lebih lanjut sebelum menentukan metode yang tepat untuk menangani missing value pada ketiga kolom tersebut.

**1.2.1. Memfilter kolom "order_approved_at"**
"""

orders_df[ orders_df.order_approved_at.isna()].head()

"""**Insight :**

Berdasarkan tabel data di atas, dapat dilihat bahwa baris data tersebut mengandung banyak informasi penting. Sekilas kolom yang memiliki missing value sama-sama memiliki **"order_status = canceled"**.

**1.2.2. Memfilter kolom "order_delivered_carrier_date"**
"""

orders_df[ orders_df.order_delivered_carrier_date.isna()].head()

"""**Insight :**

Dari tabel data di atas, didapat informasi bahwa kolom **"order_status" terdiri dari beberapa status dan kolom "order_approved_at" ternyata sebagian baris memiliki value**.

**1.2.3. Memfilter kolom "order_delivered_customer_date"**
"""

orders_df[ orders_df.order_delivered_customer_date.isna()].head()

"""**Insight :**

Jika kita membedah kolom "order_delivered_customer_date" didapat informasi bahwa kolom **"order_status" terdiri dari beberapa status, kolom "order_approved_at" sebagian barisnya memiliki value dan kolom "order_delivered_carrier_date" sebagian baris nya juga memiliki value**.

dari hasil filtering pada ketiga kolom dapat disimpulkan bahwa semua baris data dan kolom memiliki informasi penting yang bisa digunakan untuk analisa lebih lanjut, sehingga tidak dapat dibuang/dihilangkan. oleh karena itu, kita bisa menggunakan **metode interpolation (teknik yang sering digunakan pada data time series, di mana missing values diisi dengan nilai yang diinterpolasi dari data sebelum dan sesudahnya.)**.

Untuk menentukan estimasi berdasarkan pola yang ada, kita bisa memfilter datanya nya berdasarkan kolom "order_status". namun sebelumnya kita harus mengidentifikasi terlebih dahulu kolom "order_status" untuk melihat apa saja value pada kolom tersebut.
"""

orders_df.order_status.value_counts()

"""**Insight :**

Berdasarkan hasil di atas, dapat diketahui bahwa kolom **"order_status"** terdiri dari beberapa value, mulai dari **"approved"** hingga **"delivered"**. mari kita filter satu-satu berdasarkan value pada kolom tersebut.

**1.2.4. Memfilter kolom "'order_status" == approved**
"""

approved_df = orders_df[orders_df['order_status'] == 'approved']
approved_df.head()

"""**1.2.5. Memfilter kolom "'order_status" == created**"""

created_df = orders_df[orders_df['order_status'] == 'created']
created_df.head()

"""**1.2.6. Memfilter kolom "'order_status" == processing**"""

processing_df = orders_df[orders_df['order_status'] == 'processing']
processing_df.head()

"""**1.2.7. Memfilter kolom "'order_status" == invoiced**"""

invoiced_df = orders_df[orders_df['order_status'] == 'invoiced']
invoiced_df.head()

"""**1.2.8. Memfilter kolom "'order_status" == unavailable**"""

unavailable_df = orders_df[orders_df['order_status'] == 'unavailable']
unavailable_df.head()

"""**1.2.9. Memfilter kolom "'order_status" == canceled**"""

canceled_df = orders_df[orders_df['order_status'] == 'canceled']
canceled_df.head()

"""**1.2.10. Memfilter kolom "'order_status" == shipped**"""

shipped_df = orders_df[orders_df['order_status'] == 'shipped']
shipped_df.head()

"""**1.2.11. Memfilter kolom "'order_status" == delivered**"""

delivered_df = orders_df[orders_df['order_status'] == 'delivered']
delivered_df.head()

"""**Insight :**

Berdasarkan hasil filtering pada kolom "order_status" di atas, dapat disimpulkan bahwa :
1. kolom order_approved_at, order_delivered_carrier_date, dan order_delivered_customer_date **tidak semua barisnya memiliki missing value, beberapa memiliki value**.
2. dapat dilihat pada kolom waktu terkait seperti order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, dan order_estimated_delivery_date, kita bisa menganalisis selisih waktu rata-rata yang dibutuhkan untuk setiap tahap proses pesanan.

Contoh :
untuk mengisi kolom "order_approved_at", kita bisa **menghitung selisih waktu rata-rata antara kolom "order_approved_at" yang tanpa nilai NaT dengan kolom "order_purchase_timestamp"**

**1.2.12. Menghitung nilai rata-rata dari selisih waktu untuk mengisi kolom "order_approved_at"**
"""

# Filter data dengan kondisi tanpa nilai NaT
approve_time = orders_df[(orders_df['order_approved_at'].notna()) &
                             (orders_df['order_purchase_timestamp'].notna())]

# Menghitung selisih waktu dalam menit
approve_time['time_difference_minutes'] = ((approve_time['order_approved_at'] - approve_time['order_purchase_timestamp']).dt.total_seconds() / 60).astype(int)

# Menampilkan hasil untuk memastikan perhitungan
print(approve_time[['order_purchase_timestamp', 'order_approved_at', 'time_difference_minutes']].head())

"""**Insight :**

Setelah diketahui selisih waktunya, kita bisa mengambil nilai rata-rata dari selisih waktu yang dibutuhkan.
"""

# Menghitung rata-rata dari time_difference_minutes
average_time_difference_minutes = approve_time['time_difference_minutes'].mean()
# Mengubah rata-rata menjadi bilangan bulat
average_time_difference_minutes_int = int(average_time_difference_minutes)
# Menampilkan hasil rata-rata
print("Rata-rata selisih waktu (dalam menit):", average_time_difference_minutes_int)

orders_df['order_approved_at'] = orders_df.apply(
    lambda row: row['order_purchase_timestamp'] + pd.Timedelta(minutes=average_time_difference_minutes_int)
    if pd.isna(row['order_approved_at']) else row['order_approved_at'], axis=1
)

"""**Insight :**

Secara keseluruhan, perintah ini bertujuan untuk mengisi missing values pada kolom "order_approved_at" dengan estimasi waktu persetujuan berdasarkan waktu pembelian (order_purchase_timestamp) ditambah dengan selisih waktu rata-rata. **Jika nilai pada kolom order_approved_at sudah ada, maka nilai tersebut tidak akan diubah**.

Jika proses pembersihan missing value pada kolom "order_approved_at" tersebut berhasil, maka akan memperoleh hasil seperti berikut.
"""

orders_df.isna().sum()

"""Cara yang sama bisa digunakan juga untuk mengisi missing value pada kolom "order_delivered_carrier_date". kita bisa menghitung selisih waktu rata-rata antara kolom "order_delivered_carrier_date" yang tanpa nilai NaT dengan kolom "order_approved_at".

**1.2.13. Menghitung nilai rata-rata dari selisih waktu untuk mengisi kolom "order_delivered_carrier_date"**
"""

# Filter data dengan kondisi tanpa nilai NaT
carrier_time = orders_df[(orders_df['order_delivered_carrier_date'].notna()) &
                             (orders_df['order_approved_at'].notna())]

# Menghitung selisih waktu dalam menit
carrier_time['time_difference_minutes'] = ((carrier_time['order_delivered_carrier_date'] - carrier_time['order_approved_at']).dt.total_seconds() / 60).astype(int)

# Menampilkan hasil untuk memastikan perhitungan
print(carrier_time[['order_approved_at', 'order_delivered_carrier_date', 'time_difference_minutes']].head())

# Menghitung rata-rata dari time_difference_minutes
average_time_difference_minutes = carrier_time['time_difference_minutes'].mean()
average_time_difference_minutes_int = int(average_time_difference_minutes)
# Menampilkan hasil rata-rata
print("Rata-rata selisih waktu (dalam menit):", average_time_difference_minutes_int)

orders_df['order_delivered_carrier_date'] = orders_df.apply(
    lambda row: row['order_approved_at'] + pd.Timedelta(minutes=average_time_difference_minutes_int)
    if pd.isna(row['order_delivered_carrier_date']) else row['order_delivered_carrier_date'], axis=1
)

"""Jika proses pembersihan missing value pada kolom "order_delivered_carrier_date" tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

orders_df.isna().sum()

"""**1.2.14. Menghitung nilai rata-rata dari selisih waktu untuk mengisi kolom "order_delivered_customer_date"**"""

# Filter data dengan kondisi tanpa nilai NaT
customer_time = orders_df[(orders_df['order_delivered_customer_date'].notna()) &
                             (orders_df['order_delivered_carrier_date'].notna())]

# Menghitung selisih waktu dalam menit
customer_time['time_difference_minutes'] = ((customer_time['order_delivered_customer_date'] - customer_time['order_delivered_carrier_date']).dt.total_seconds() / 60).astype(int)

# Menampilkan hasil untuk memastikan perhitungan
print(customer_time[['order_delivered_carrier_date', 'order_delivered_customer_date', 'time_difference_minutes']].head())

# Menghitung rata-rata dari time_difference_minutes
average_time_difference_minutes = customer_time['time_difference_minutes'].mean()
average_time_difference_minutes_int = int(average_time_difference_minutes)
# Menampilkan hasil rata-rata
print("Rata-rata selisih waktu (dalam menit):", average_time_difference_minutes_int)

orders_df['order_delivered_customer_date'] = orders_df.apply(
    lambda row: row['order_delivered_carrier_date'] + pd.Timedelta(minutes=average_time_difference_minutes_int)
    if pd.isna(row['order_delivered_customer_date']) else row['order_delivered_customer_date'], axis=1
)

"""Jika proses pembersihan missing value pada kolom "order_delivered_customer_date" tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

orders_df.isna().sum()

"""**2. Membersihkan data geolokasi_df**

Berdasarkan hasil proses assessing data, diketahui bahwa hanya terdapat satu masalah yang dijumpai dalam geolokasi_df, yaitu duplicate data.

**2.1. Menangani duplicate data**
"""

geolokasi_df.drop_duplicates(inplace=True)

"""kode di atas akan menghasilkan keluaran seperti berikut “Jumlah duplikasi:  0”."""

print("Jumlah duplikasi: ",geolokasi_df.duplicated().sum())

geolokasi_df.info()

"""**3. Membersihkan data order_item_df**

Berdasarkan hasil proses assessing data, diketahui bahwa hanya terdapat satu masalah yang dijumpai dalam order_item_df, yaitu tipe data.

**3.1. Menangani tipe data**
"""

datetime_columns = ["shipping_limit_date"]

for column in datetime_columns:
  order_item_df[column] = pd.to_datetime(order_item_df[column])

order_item_df.info()

"""**4. Membersihkan data review_df**

Berdasarkan hasil proses assessing data, diketahui bahwa terdapat dua masalah yang dijumpai dalam review_df, yaitu tipe data, dan missing value.

**4.1. Menangani tipe data**
"""

datetime_columns = ["review_creation_date", "review_answer_timestamp"]

for column in datetime_columns:
   review_df[column] = pd.to_datetime( review_df[column])

"""**4.2. Menangani missing value**

Untuk menentukan metode mana yang akan digunakan, kita perlu melihat data yang mengandung missing value tersebut menggunakan teknik filtering seperti berikut.

**4.2.1. Memfilter kolom "review_comment_title"**
"""

review_df[review_df.review_comment_title.isna()].head()

"""**Insight :**

dari hasil filtering dapat disimpulkan bahwa :
1. Banyak ulasan yang tidak memiliki judul (review_comment_title), tetapi tetap memiliki skor ulasan (review_score). Ini menunjukkan bahwa pelanggan mungkin merasa cukup puas atau tidak puas untuk memberikan skor, tetapi tidak merasa perlu untuk memberikan judul ulasan.
2. hal yang sama juga bisa berlaku untuk kolom "review_comment_message".

untuk lebih memastikan, bisa mengidentifikasi nilai-nilai yang terdapat pada kolom "review_comment_title" tersebut.
"""

review_df.review_comment_title.value_counts()

"""**Insight :**

dari data di atas dapat dilihat bahwa isi pada kolom "review_comment_title" cukup variatif. sehingga dapat dilakukan **metode menghapus kolom tersebut** dengan pertimbangan :
1. jika dilihat dari hasil analisa sebelumnya bahwa pelanggan **mungkin merasa cukup puas atau tidak puas untuk memberikan skor, tetapi tidak merasa perlu untuk memberikan judul ulasan**.
2. dapat menggunakan kolom "review_score" sebagai acuan untuk analisa lanjutan.
"""

review_df = review_df.drop(columns=['review_comment_title'])

"""**4.2.2. Memfilter kolom "review_comment_message"**"""

review_df[review_df.review_comment_message.isna()].head()

"""untuk lebih memastikan, bisa mengidentifikasi nilai-nilai yang terdapat pada kolom "review_comment_message" tersebut."""

review_df.review_comment_message.value_counts()

"""**Insight :**

dari data di atas dapat dilihat bahwa isi pada kolom "review_comment_message" juga cukup variatif. sehingga dapat dilakukan **metode menghapus kolom tersebut** dengan pertimbangan :
1. jika dilihat dari hasil analisa sebelumnya bahwa pelanggan **mungkin merasa cukup puas atau tidak puas untuk memberikan skor, tetapi tidak merasa perlu untuk memberikan pesan ulasan**.
2. dapat menggunakan kolom "review_score" sebagai acuan untuk analisa lanjutan.
"""

review_df = review_df.drop(columns=['review_comment_message'])

"""Jika proses pembersihan missing value pada kedua kolom tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

review_df.isna().sum()

"""**5. Membersihkan data produk_df**

Berdasarkan hasil proses assessing data, diketahui bahwa hanya terdapat satu masalah yang dijumpai dalam produk_df, yaitu missing value.

**5.1. Menangani missing value pada kolom"product_category_name"**
"""

produk_df[produk_df.product_category_name.isna()].head()

"""Dikarenakan kolom ""product_category_name" merupakan kolom kategorik, dapat **menggunakan nilai yang dominan sebagai pengganti missing value tersebut**."""

produk_df.product_category_name.value_counts().head()

"""**Insight :**

Berdasarkan hasil di atas, dapat diketahui bahwa **nilai yang paling dominan dalam kolom "product_category_name" adalah “cama_mesa_banho”**. Nilai inilah yang selanjutnya akan kita gunakan sebagai pengganti missing value.
"""

produk_df['product_category_name'] = produk_df['product_category_name'].fillna('cama_mesa_banho')

"""Jika proses pembersihan missing value pada kolom tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

produk_df.isna().sum()

"""**5.2. Menangani missing value pada kolom"product_name_lenght" dan "product_description_lenght"**

**Insight :**

Untuk kedua kolom ini, kita dapat menggunakan metode **dropping** dengan pertimbangan :
1. Kolom "product_name_lenght" mengacu pada panjang nama produk. Ini biasanya diukur dalam jumlah karakter yang digunakan untuk nama produk tersebut. Misalnya, jika nama produk adalah "Laptop Dell Inspiron 15", panjang nama produk tersebut adalah 23 karakter. hal ini tidak terlalu penting untuk analisa.
2. Hal tersebut berlaku juga untuk kolom "product_description_lenght"
"""

produk_df = produk_df.drop(columns=['product_name_lenght', 'product_description_lenght'])

"""Jika proses pembersihan missing value pada kedua kolom tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

produk_df.isna().sum()

"""**5.3. Menangani missing value pada kolom"product_photos_qty"**"""

produk_df[produk_df.product_photos_qty.isna()].head()

"""**Insight :**

Untuk mengatasi missing value pada kolom berikut, dapat menggunakan 2 cara :
1. dropping, dikarenakan kolom ini mengacu pada jumlah foto pada produk dimana data ini tidak terlalu berpengaruh dalam analisa.
2. diganti dengan nilai yang dominan, dikarenakan nilai yang terdapat pada kolom nya tidak terlalu variatif sehingga tidak terlalu sulit untuk menentukan pengganti value nya.
"""

produk_df.product_photos_qty.value_counts().head()

"""untuk kebutuhkan analisa saat ini, maka kolom "product_photos_qty" dihapuskan."""

produk_df = produk_df.drop(columns=['product_photos_qty'])

"""Jika proses pembersihan missing value pada kolom tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

produk_df.isna().sum()

"""**5.4. Menangani missing value pada kolom"product_weight_g", "product_length_cm", "product_height_cm", dan "product_width_cm"**

Untuk menangani missing value pada keempat kolom ini, dapat dilakukan filter terlebih dahulu pada masing-masing kolom
"""

produk_df[produk_df.product_weight_g.isna()]

produk_df[produk_df.product_length_cm.isna()]

produk_df[produk_df.product_height_cm.isna()]

produk_df[produk_df.product_width_cm.isna()]

"""**Insight :**

dari semua hasil filtering diatas, **4 kolom yang memiliki missing value ternyata berada di baris yang sama**. untuk menangani nya kita bisa lakukan pengecekan lebih lanjut untuk memastikan metode yang akan kita gunakan nantinya.

**5.4.1. Pengecekan menggunakanlah method value_counts()untuk mengidentifikasi nilai yang dominan.**
"""

produk_df.product_weight_g.value_counts()

produk_df.product_length_cm.value_counts()

produk_df.product_height_cm.value_counts()

produk_df.product_width_cm.value_counts()

"""**Insight :**

dari keempat hasil di atas, didapat kesimpulan :
1. ternyata masing-masing kolom memiliki value yang sangat variatif, sehingga belum bisa menentukan metode apa untuk mengatasi missing value.
2. untuk lebih memastikan lagi kita bisa memfilter berdasarkan kolom "product_category_name" (mengingat dari hasil filtering sebelumnya, terdapat 2 kategori produk) untuk mengetahui apakah ada pengaruhnya untuk menentukan metode yang akan digunakan untuk mengisi missing value pada keempat kolom tersebut.

**5.4.2. Pengecekan dengan memfilter berdasarkan kolom "product_category_name**
"""

produk_bebes_df = produk_df[produk_df['product_category_name'] == 'bebes']
produk_bebes_df.head()

produk_cama_mesa_banho_df = produk_df[produk_df['product_category_name'] == 'cama_mesa_banho']
produk_cama_mesa_banho_df.head()

"""**Insight :**

dari kedua filter di atas, didapat kesimpulan :
1. ternyata hasil yang didapat dari dua pengecekan pada keempat kolom yang dimaksud memiliki value yang sangat variatif.
2. setelah benar-benar dipastikan, maka untuk menangani missing value pada keempat kolom bisa menggunakan metode **imputation** (Mengisi missing value dengan nilai tertentu, seperti mean, median, modus, atau nilai tetap lainnya).
"""

mean_weight = produk_df['product_weight_g'].mean()
mean_length = produk_df['product_length_cm'].mean()
mean_height = produk_df['product_height_cm'].mean()
mean_width = produk_df['product_width_cm'].mean()

# Mengganti missing value pada kolom-kolom tersebut dengan nilai rata-rata
produk_df['product_weight_g'] = produk_df['product_weight_g'].fillna(mean_weight)
produk_df['product_length_cm'] = produk_df['product_length_cm'].fillna(mean_length)
produk_df['product_height_cm'] = produk_df['product_height_cm'].fillna(mean_height)
produk_df['product_width_cm'] = produk_df['product_width_cm'].fillna(mean_width)

"""Jika proses pembersihan missing value pada keempat kolom tersebut berhasil, maka akan memperoleh hasil seperti berikut."""

produk_df.isna().sum()

"""### Exploratory Data Analysis (EDA)

**Eksplorasi Data customer_df**
"""

customer_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 99,441 pelanggan unik.
2. Pelanggan tersebar di berbagai kota dan negara bagian. Kolom customer_city dan customer_state memberikan informasi tentang lokasi geografis pelanggan.
3. Kolom customer_zip_code_prefix menunjukkan kode pos pelanggan, yang bisa digunakan untuk analisis lebih lanjut tentang distribusi geografis dan logistik pengiriman.
4. Kolom customer_unique_id menunjukkan bahwa setiap pelanggan memiliki ID unik, yang bisa digunakan untuk melacak pembelian berulang dan analisis loyalitas pelanggan.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Kota dengan jumlah customer terbanyak**
"""

customer_df.groupby(by="customer_city").customer_id.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Pelanggan yang dimiliki terbanyak berasal dari kota sao paulo. Ini menunjukkan kota tersebut memiliki basis pelanggan yang besar dan potensial untuk pemasaran lebih lanjut.
2. Kota-kota dengan jumlah pelanggan yang tinggi menunjukkan potensi pasar yang besar. Ini bisa menjadi fokus untuk ekspansi bisnis dan peningkatan layanan.

- **Negara dengan jumlah customer terbanyak**
"""

customer_df.groupby(by="customer_state").customer_id.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Negara dengan jumlah pelanggan terbanyak berada di negara SP. Ini menunjukkan kota tersebut memiliki basis pelanggan yang besar dan potensial untuk pemasaran lebih lanjut.
2. Negara dengan jumlah pelanggan yang tinggi menunjukkan potensi pasar yang besar. Ini bisa menjadi fokus untuk ekspansi bisnis dan peningkatan layanan.

**Eksplorasi Data geolokasi_df**
"""

geolokasi_df.describe(include="all")

"""**Insight :**

1. Kolom geolocation_zip_code_prefix menunjukkan distribusi kode pos yang luas, dengan nilai minimum 1001 dan maksimum 99990.
2. Kolom geolocation_lat dan geolocation_lng memberikan informasi tentang koordinat geografis (latitude dan longitude) dari setiap kode pos. Nilai latitude berkisar dari -36.60537 hingga 45.06593, sedangkan nilai longitude berkisar dari -101.4668 hingga 121.1054.
3. Kolom geolocation_city dan geolocation_state memberikan informasi tentang kota dan negara bagian yang terkait dengan setiap kode pos.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Kota dengan jumlah kode pos terbanyak**
"""

geolokasi_df.groupby(by="geolocation_city").geolocation_zip_code_prefix.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Kota dengan jumlah kode pos unik terbanyak berada di sao paulo. Ini menunjukkan kota tersebut memiliki distribusi geografis yang luas dan beragam.
2. Kota dengan jumlah kode pos yang tinggi menunjukkan potensi pasar yang besar.

- **Negara dengan jumlah kode pos terbanyak**
"""

geolokasi_df.groupby(by="geolocation_state").geolocation_zip_code_prefix.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Negara dengan jumlah kode pos unik terbanyak berada di SP. Ini menunjukkan kota tersebut memiliki distribusi geografis yang luas dan beragam.
2. Negara dengan jumlah kode pos yang banyak menunjukkan potensi pasar yang besar.

**Eksplorasi Data seller_df**
"""

seller_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 3,095 penjual.
2. Kolom seller_zip_code_prefix menunjukkan distribusi kode pos yang luas, dengan nilai minimum 1001 dan maksimum 99730.
3. Kolom seller_city dan seller_state memberikan informasi tentang kota dan negara bagian yang terkait dengan setiap penjual.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Kota dengan jumlah penjual terbanyak**
"""

seller_df.groupby(by="seller_city").seller_id.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Kota dengan jumlah penjual terbanyak berada di sao paulo. Ini menunjukkan kota tersebut memiliki basis penjual yang besar dan beragam.
2. Kota-kota dengan jumlah penjual yang tinggi menunjukkan potensi pasar yang besar.

- **Negara dengan jumlah penjual terbanyak**
"""

seller_df.groupby(by="seller_state").seller_id.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Negara dengan jumlah penjual terbanyak berada di SP. Ini menunjukkan negara tersebut memiliki basis penjual yang besar dan beragam.
2. Negara dengan jumlah penjual yang tinggi menunjukkan potensi pasar yang besar.

**Eksplorasi Data produk_df**
"""

produk_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 32,951 produk unik.
2. Kolom product_weight_g menunjukkan berat produk yang bervariasi, dengan rata-rata sekitar 2,276 gram. Berat produk teringan adalah 0 gram, sedangkan yang terberat adalah 40,425 gram.
3. Kolom product_length_cm, product_height_cm, dan product_width_cm menunjukkan dimensi produk yang bervariasi. Rata-rata panjang produk adalah sekitar 30 cm, tinggi produk sekitar 17 cm, dan lebar produk sekitar 23 cm.

**Eksplorasi Data kategori_produk_df**
"""

kategori_produk_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 71 kategori produk unik
2. Kolom product_category_name dan product_category_name_english menunjukkan bahwa setiap kategori produk memiliki nama dalam bahasa asli dan terjemahannya dalam bahasa Inggris. Ini memudahkan analisis lebih lanjut dan pemahaman tentang kategori produk yang berbeda.
3. Kategori produk yang paling sering muncul adalah beleza_saude (health_beauty), yang menunjukkan bahwa produk kecantikan dan kesehatan mungkin menjadi salah satu kategori yang paling populer di dataset ini.

**Menggabungkan Dataset produk_df dan kategori_produk_df**

Jika diperhatikan, antara dataset produk_df dan kategori_produk_df memiliki hubungan. kedua dataset ini dapat digabungkan berdasarkan kolom yang sama yaitu "product_category_name". Dengan menggabungkan kedua dataset ini, maka bisa menambahkan informasi tambahan dari kategori_produk_df ke produk_df, seperti nama kategori produk dalam bahasa Inggris.
"""

produk_baru_df = pd.merge(produk_df, kategori_produk_df, on='product_category_name')

"""rangkuman parameter statistik dari produk_baru_df :"""

produk_baru_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 32,938 produk unik..
2. Terdapat 71 kategori produk unik. Kategori dengan jumlah produk terbanyak adalah bed_bath_table dengan 3,639 produk.
3. Kolom product_weight_g menunjukkan berat produk yang bervariasi, dengan rata-rata sekitar 2,276 gram. Berat produk teringan adalah 0 gram, sedangkan yang terberat adalah 40,425 gram.
4. Kolom product_length_cm, product_height_cm, dan product_width_cm menunjukkan dimensi produk yang bervariasi. Rata-rata panjang produk adalah sekitar 30.82 cm, tinggi produk sekitar 16.93 cm, dan lebar produk sekitar 23.20 cm. Dimensi produk terpendek adalah 7 cm (panjang), 2 cm (tinggi), dan 6 cm (lebar), sedangkan dimensi produk terpanjang adalah 105 cm (panjang), 105 cm (tinggi), dan 118 cm (lebar).

**Berikut informasi yang bisa didapat dari data di atas :**

- **Kategori produk dengan jumlah produk terbanyak.**
"""

produk_baru_df.groupby(by="product_category_name_english").product_id.nunique().sort_values(ascending=False).reset_index().head()

"""**Insight :**

1. Kategori produk dengan jumlah produk terbanyak didonimasi oleh bed_bath_table sebanyak 3639.
2. Kategori dengan jumlah produk yang tinggi menunjukkan potensi pasar yang besar.

**Eksplorasi Data order_item_df**
"""

order_item_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,650 item pesanan unik
2. Kolom price menunjukkan harga produk yang bervariasi, dengan rata-rata sekitar 120.65. Harga produk terendah adalah 0.85, sedangkan yang tertinggi adalah 6,735.
3. Kolom freight_value menunjukkan biaya pengiriman yang bervariasi, dengan rata-rata sekitar 19.99. Biaya pengiriman terendah adalah 0, sedangkan yang tertinggi adalah 409.68.
4. Kolom order_item_id menunjukkan bahwa sebagian besar pesanan hanya memiliki satu item, dengan nilai rata-rata sekitar 1.2

**Eksplorasi Data orders_df**
"""

orders_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 99,441 pesanan unik.
2. Kolom order_status menunjukkan bahwa sebagian besar pesanan memiliki status "delivered", yang menunjukkan tingkat penyelesaian pesanan yang tinggi.
3. Kolom order_purchase_timestamp menunjukkan distribusi waktu pembelian pesanan. Ini bisa digunakan untuk analisis tren pembelian berdasarkan waktu.

**Menggabungkan Dataset orders_df dan order_item_df**

Sama seperti hal nya dataset produk_df dan kategori_produk_df, maka dataset orders_df dan order_item_df juga bisa digabungkan berdasarkan kolom yang sama yaitu "order_id" dan menjadi dataset baru bernama dataset "order_baru_df".
"""

order_baru_df = pd.merge(orders_df, order_item_df, on='order_id')

"""rangkuman parameter statistik dari order_baru_df :"""

order_baru_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,650 pesanan.
2. Kolom order_status menunjukkan bahwa sebagian besar pesanan memiliki status "delivered", yang menunjukkan tingkat penyelesaian pesanan yang tinggi.
3. Kolom order_purchase_timestamp menunjukkan distribusi waktu pembelian pesanan. Ini bisa digunakan untuk analisis tren pembelian berdasarkan waktu.
4. Kolom price menunjukkan harga produk yang bervariasi, dengan rata-rata sekitar 120.65. Harga produk terendah adalah 0.85, sedangkan yang tertinggi adalah 6,735.
5. Kolom freight_value menunjukkan biaya pengiriman yang bervariasi, dengan rata-rata sekitar 19.99. Biaya pengiriman terendah adalah 0, sedangkan yang tertinggi adalah 409.68.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Jumlah unik untuk setiap status pesanan**
"""

order_baru_df.groupby(by="order_status").agg({
    "customer_id": "nunique",
    "order_id": "nunique",
    "product_id": "nunique",
    "seller_id": "nunique"
})

"""**Insight :**

1. Status "delivered" memiliki jumlah pelanggan, pesanan, produk, dan penjual terbanyak. Ini menunjukkan bahwa sebagian besar pesanan berhasil dikirimkan dan diterima oleh pelanggan.
2. Status "canceled" memiliki jumlah yang cukup signifikan, dengan 461 pesanan dibatalkan. Ini bisa menjadi area yang perlu dianalisis lebih lanjut untuk memahami alasan pembatalan dan mencari cara untuk menguranginya.
3. Status "shipped" menunjukkan bahwa ada 1,106 pesanan yang sedang dalam proses pengiriman. Ini menunjukkan efisiensi logistik dan pengiriman yang baik.
4. Status "unavailable" memiliki jumlah yang sangat kecil, menunjukkan bahwa hanya sedikit pesanan yang tidak tersedia.

- **Distribusi pesanan, harga produk, dan biaya pengiriman berdasarkan status pesanan.**
"""

order_baru_df.groupby(by="order_status").agg({
    "order_id": "nunique",
    "price": ["max", "min", "mean", "std"],
    "freight_value": ["max", "min", "mean", "std"]
})

"""**Insight :**

1. Status "delivered" memiliki jumlah pesanan terbanyak (96,478 pesanan) dengan harga produk bervariasi dari 0.85 hingga 6,735, dan biaya pengiriman bervariasi dari 0 hingga 409.68. Rata-rata harga produk adalah 119.98 dengan standar deviasi 182.30, sedangkan rata-rata biaya pengiriman adalah 19.95 dengan standar deviasi 15.70.
2. Status "approved" memiliki 2 pesanan dengan harga produk bervariasi dari 19.85 hingga 169.90, dan biaya pengiriman bervariasi dari 9.56 hingga 10.96. Rata-rata harga produk adalah 69.87 dengan standar deviasi 86.63, sedangkan rata-rata biaya pengiriman adalah 10.49 dengan standar deviasi 0.81.
3. Status "canceled" memiliki 461 pesanan dengan harga produk bervariasi dari 5.53 hingga 2,649, dan biaya pengiriman bervariasi dari 0.03 hingga 171.88. Rata-rata harga produk adalah 175.71 dengan standar deviasi 323.31, sedangkan rata-rata biaya pengiriman adalah 19.65 dengan standar deviasi 17.58.
   
dst.

**Menggabungkan Dataset order_baru_df dan produk_baru_df**

Dataset order_baru_df dan produk_baru_df bisa digabungkan menggunakan kolom yang sama yaitu "produk_id" dan menjadi satu dataset baru bernama " order_produk_baru_df" untuk mendapatkan informasi detail produk yang dipesan.
"""

order_produk_baru_df = pd.merge(order_baru_df, produk_baru_df, on='product_id')

"""rangkuman parameter statistik dari order_baru_df :"""

order_produk_baru_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,626 pesanan.
2. order_status menunjukkan bahwa sebagian besar pesanan memiliki status "delivered", yang menunjukkan tingkat penyelesaian pesanan yang tinggi.
3. Terdapat 71 kategori produk unik. Kategori dengan jumlah produk terbanyak adalah bed_bath_table dengan 12,718 produk.
4. olom product_weight_g menunjukkan berat produk yang bervariasi, dengan rata-rata sekitar 2,093.62 gram. Berat produk teringan adalah 0 gram, sedangkan yang terberat adalah 40,425 gram.
5. Kolom price menunjukkan harga produk yang bervariasi, dengan rata-rata sekitar 120.63. Harga produk terendah adalah 0.85, sedangkan yang tertinggi adalah 6,735.
6. Kolom freight_value menunjukkan biaya pengiriman yang bervariasi, dengan rata-rata sekitar 19.99. Biaya pengiriman terendah adalah 0, sedangkan yang tertinggi adalah 409.68.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Kategori produk yang paling banyak di order.**
"""

order_produk_baru_df.groupby(by="product_category_name_english").order_id.count().sort_values(ascending=False).reset_index().head(5)

"""**Insight :**

1. Kategori produk dengan jumlah produk terbanyak adalah bed_bath_table sebanyak 12.718.
2. Kategori dengan jumlah produk yang tinggi menunjukkan potensi pasar yang besar

- **Jumlah produk, dan penjual untuk setiap kategori produk**
"""

order_produk_baru_df.groupby(by="product_category_name_english").agg({
    "product_id": "nunique",
    "seller_id": "nunique"
})

"""**Insight :**

Masing-masing kategori ini memiliki jumlah produk dan penjual yang sangat variatif, menunjukkan adanya variasi produk yang sangat luas yang ditawarkan oleh banyak penjual.

- **Kategori produk berdasarkan jumlah pesanan, harga produk, dan biaya pengiriman**
"""

order_produk_baru_df.groupby(by="product_category_name_english").agg({
    "order_id": "nunique",
    "price": ["sum", "max", "min", "mean", "std"],
    "freight_value": ["sum", "max", "min", "mean", "std"]
})

"""**Insight :**

1. Kategori "Watches Gifts" memiliki total penjualan tertinggi dengan nilai penjualan mencapai 1,205,005.68 dan harga produk tertinggi sebesar 3,999.90. Rata-rata harga produk dalam kategori ini adalah 201.14 dengan standar deviasi 256.74. Biaya pengiriman total untuk kategori ini adalah 100,535.93 dengan biaya pengiriman tertinggi sebesar 209.63.
2. Kategori "Telephony" memiliki total penjualan sebesar 323,667.53 dan harga produk tertinggi sebesar 2,428. Rata-rata harga produk dalam kategori ini adalah 71.21 dengan standar deviasi 135.77. Biaya pengiriman total untuk kategori ini adalah 71,215.79 dengan biaya pengiriman tertinggi sebesar 121.22.

dst.

- **Distribusi dan variasi pesanan berdasarkan kategori produk dan status pesanan nya.**
"""

order_produk_baru_df.groupby(by=["product_category_name_english", "order_status"]).agg({
    "order_id": "nunique",
    "product_id": "nunique",
    "seller_id": "nunique"
})

"""**Insight :**

Pivot table di atas memberikan gambaran terkait detail jumlah pesanan, jumlah produk yang dipesan serta jumlah penjual yang variatif untuk setiap status pesanan berdasarkan kategori produknya.

**Menggabungkan Dataset order_produk_baru_df dan customer_df**

Pada tahap ini, kita akan mengeksplorasi data order_produk_baru_df dan customer_df. Dengan menggabungkan 2 dataset tersebut, memungkinkan untuk melakukan segmentasi pelanggan berdasarkan berbagai kriteria seperti lokasi geografis, nilai pesanan, dan kategori produk yang dibeli. Hal ini juga bisa membantu dalam memahami area dengan permintaan tertinggi.
"""

order_produk_baru_cust_df = pd.merge(customer_df, order_produk_baru_df, on='customer_id')

"""rangkuman parameter statistik dari order_produk_baru_cust_df :"""

order_produk_baru_cust_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,626 pesanan.
2. Terdapat 98,645 pelanggan dan 95,400 pelanggan unik berdasarkan customer_unique_id.
3. Pelanggan berasal dari 4,110 kota yang berbeda dan 27 negara bagian yang berbeda. Kota dengan jumlah pelanggan terbanyak adalah Sao Paulo (17,807 pelanggan) dan negara bagian dengan jumlah pelanggan terbanyak adalah SP (47,437 pelanggan).
4. Sebagian besar pesanan memiliki status "delivered" (110,175 pesanan), menunjukkan tingkat penyelesaian pesanan yang tinggi.
5. Kolom order_purchase_timestamp menunjukkan distribusi waktu pembelian pesanan, dengan rata-rata waktu pembelian pada 2017-12-31.
6. Terdapat 71 kategori produk unik. Kategori dengan jumlah produk terbanyak adalah bed_bath_table dengan 12,718 produk.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Jumlah pelanggan berdasarkan kategori produk**
"""

order_produk_baru_cust_df.groupby(by="product_category_name_english").customer_id.nunique().sort_values(ascending=False).reset_index().head(5)

"""**Insight :**

Berdasarkan hasil tersebut diketahui bahwa bed_bath_table yang paling banyak diminati.

- **Distribusi dan variasi pesanan berdasarkan kategori produk dan lokasi geografis pelanggan.**
"""

order_produk_baru_cust_df.groupby(by=["product_category_name_english", "customer_city"]).agg({
    "customer_id": "nunique",
    "order_id": "nunique",
    "seller_id": "nunique"
})

"""**Insight :**

1. Data ini menunjukkan bahwa beberapa kota memiliki jumlah pelanggan, pesanan, dan penjual yang sama untuk kategori produk tertentu. Misalnya, kota seperti Alto Piquiri, Americana, Amparo, Andradas, dan Andradina masing-masing memiliki 1 pelanggan, 1 pesanan, dan 1 penjual untuk kategori "Agro Industry and Commerce".
2. Beberapa kota seperti Xavantina, Xaxim, dan Xinguara memiliki 1 pelanggan, 1 pesanan, dan 1 penjual untuk kategori produk tertentu, menunjukkan bahwa ada beberapa kota dengan aktivitas pembelian yang rendah

- **distribusi pelanggan berdasarkan kategori produk.**
"""

order_produk_baru_cust_df.groupby(by=["product_category_name_english"]).agg({
    "customer_id": "nunique",
    "customer_unique_id": "nunique"
})

"""**Insight :**

Data ini juga menunjukkan jumlah pelanggan unik berdasarkan ID unik pelanggan (customer_unique_id) untuk setiap kategori produk. Ini membantu dalam mengidentifikasi pelanggan yang melakukan pembelian berulang dalam kategori produk yang sama.

**Menggabungkan Dataset order_produk_baru_df dan seller_df**

Pada tahap ini, kita akan mengeksplorasi data order_produk_baru_df dan seller_df. Dengan menggabungkan 2 dataset tersebut, memungkinkan untuk melakukan segmentasi penjual berdasarkan berbagai kriteria seperti lokasi geografis, nilai pesanan, dan kategori produk yang dibeli. Hal ini juga bisa membantu dalam memahami area dengan penjualan tertinggi.
"""

order_produk_baru_seller_df = pd.merge(order_produk_baru_df, seller_df, on='seller_id')

"""rangkuman parameter statistik dari order_produk_baru_seller_df :"""

order_produk_baru_seller_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,650 pesanan.
2. Mencakup 611 kota penjual unik dan 23 negara bagian penjual unik. Kota dengan jumlah penjual terbanyak adalah Sao Paulo (27,976 penjual), dan negara bagian dengan jumlah penjual terbanyak adalah SP (80,318 penjual).

**Berikut informasi yang bisa didapat dari data di atas :**

- **Jumlah penjual berdasarkan kategori produk**
"""

order_produk_baru_seller_df.groupby(by="product_category_name_english").seller_id.nunique().sort_values(ascending=False).reset_index().head(5)

"""**Insight :**

Berdasarkan hasil tersebut diketahui bahwa health_beauty memiliki 492 penjual. Ini menunjukkan bahwa produk-produk dalam kategori kesehatan dan kecantikan sangat populer.

- **Distribusi pelanggan dan penjual berdasarkan kategori produk dan lokasi geografis penjual.**
"""

order_produk_baru_seller_df.groupby(by=["product_category_name_english", "seller_city"]).agg({
    "customer_id": "nunique",
    "seller_id": "nunique"
})

"""**Insight :**

1. Pada kategori "Watches Gifts", Kota Sumare memiliki jumlah pelanggan yang sangat tinggi, yaitu 579 pelanggan unik, namun hanya 1 penjual unik. Ini menunjukkan bahwa satu penjual melayani banyak pelanggan di kota ini, yang bisa menjadi peluang untuk meningkatkan jumlah penjual.
2. Pada kategori "Watches Gifts", Kota Sorocaba memiliki 8 pelanggan unik dan 1 penjual unik. Ini menunjukkan bahwa satu penjual melayani beberapa pelanggan di kota ini.
3. Rata-rata di setiap kota, menunjukkan bahwa satu penjual melayani beberapa pelanggan.

**Eksplorasi Data review_df**
"""

review_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 99,224 ulasan.
2. Skor ulasan bervariasi dari 1 hingga 5, dengan rata-rata skor ulasan sekitar 4.09. Ini menunjukkan bahwa sebagian besar ulasan cenderung positif
3. 25% ulasan memiliki skor 4. 50% ulasan memiliki skor 5. 75% ulasan memiliki skor 5. Skor ulasan terendah adalah 1, dan skor ulasan tertinggi adalah 5.
4. Tanggal pembuatan ulasan bervariasi dari 2016-10-02 hingga 2018-08-31, dengan rata-rata tanggal pembuatan ulasan pada 2018-01-12
5. Tanggal jawaban ulasan bervariasi dari 2016-10-07 hingga 2018-10-29, dengan rata-rata tanggal jawaban ulasan pada 2018-01-16
6. Ulasan dengan review_id dan order_id tertentu muncul lebih dari sekali, dengan frekuensi tertinggi adalah 3 kali.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Jumlah order berdasarkan review score**
"""

review_df.groupby(by="review_score").order_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

1. Terdapat 57,076 ulasan dengan skor 5, menunjukkan bahwa sebagian besar pelanggan sangat puas dengan pesanan mereka.
2. Sebagian besar ulasan memiliki skor tinggi (4 dan 5), menunjukkan tingkat kepuasan pelanggan yang tinggi secara keseluruhan.
3. Namun, ada juga sejumlah ulasan dengan skor rendah (1 dan 2), yang menunjukkan adanya masalah atau ketidakpuasan pelanggan yang perlu diperhatikan.

**Menggabungkan Dataset review_df dan order_produk_baru_df**

Pada tahap ini, kita akan mengeksplorasi data order_produk_baru_df dan review_df.
1. Dengan menggabungkan 2 dataset tersebut, bisa mendapatkan wawasan yang lebih mendalam tentang kepuasan pelanggan. Ini termasuk analisis skor ulasan berdasarkan kategori produk, penjual, dan lokasi geografis.
2. Data gabungan juga memungkinkan untuk melakukan segmentasi pelanggan berdasarkan skor ulasan dan riwayat pembelian mereka. Ini membantu dalam mengidentifikasi pelanggan yang paling puas dan yang paling tidak puas.
3. Bisa juga menganalisis hubungan antara waktu pengiriman dan skor ulasan. Ini membantu dalam memahami apakah keterlambatan pengiriman mempengaruhi kepuasan pelanggan.
"""

review_produk_df = pd.merge(review_df, order_produk_baru_df, on='order_id')

"""rangkuman parameter statistik dari review_produk_df :"""

review_produk_df.describe(include="all")

"""**Insight :**

1. Dataset ini memiliki total 112,348 ulasan dan pesanan.
2. Skor ulasan bervariasi dari 1 hingga 5, dengan rata-rata skor ulasan sekitar 4.03. Ini menunjukkan bahwa sebagian besar ulasan cenderung positif.
3. 25% ulasan memiliki skor 4. 50% ulasan memiliki skor 5. 75% ulasan memiliki skor 5. Skor ulasan terendah adalah 1, dan skor ulasan tertinggi adalah 5.
4. rata-rata tanggal pembuatan ulasan pada 2018-01-13
5. rata-rata tanggal jawaban ulasan pada 2018-01-16
6. rata-rata waktu pembelian pada 2017-12-31 dan rata-rata waktu persetujuan pada 2018-01-01
7. jumlah produk terbanyak adalah bed_bath_table dengan 12,735 produk
8. Sebagian besar pesanan memiliki status "delivered" (109,991 pesanan), menunjukkan tingkat penyelesaian pesanan yang tinggi.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Distribusi ulasan berdasarkan skor ulasan**
"""

review_produk_df.groupby(by="review_score").review_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

1. Terdapat 56,847 ulasan dengan skor 5, menunjukkan bahwa sebagian besar pelanggan sangat puas dengan pesanan mereka.
2. Sebagian besar ulasan memiliki skor tinggi (4 dan 5), menunjukkan tingkat kepuasan pelanggan yang tinggi secara keseluruhan.
3. ada juga sejumlah ulasan dengan skor rendah (1 dan 2), yang menunjukkan adanya masalah atau ketidakpuasan pelanggan.

- **Distribusi pelanggan berdasarkan skor ulasan**
"""

review_produk_df.groupby(by="review_score").customer_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

1. Terdapat 56,999 pelanggan unik yang memberikan ulasan dengan skor 5. Ini menunjukkan bahwa sebagian besar pelanggan sangat puas dengan pesanan mereka.
2. Terdapat 10,850 pelanggan unik yang memberikan ulasan dengan skor 1. Ini menunjukkan bahwa ada sejumlah pelanggan yang sangat tidak puas dengan pesanan mereka.
3. Sebagian besar ulasan memiliki skor tinggi (4 dan 5), ada juga sejumlah ulasan dengan skor rendah (1 dan 2).

- **Berapa banyak penjual dan produk yang menerima ulasan dengan skor tertentu**
"""

review_produk_df.groupby(by=["review_score"]).agg({
    "seller_id": "nunique",
    "product_id": "nunique"
})

"""**Insight :**

1. Skor ulasan 1 menunjukkan ketidakpuasan pelanggan yang signifikan. Banyak penjual dan produk yang menerima ulasan negatif ini, yang menunjukkan adanya masalah yang perlu diperbaiki.
2. Skor ulasan 5 menunjukkan kepuasan pelanggan yang sangat tinggi. Penjual dan produk yang menerima ulasan ini sudah sangat baik dan berhasil memenuhi atau bahkan melebihi ekspektasi pelanggan

- **Identifikasi kategori produk yang paling populer/memuaskan dan yang tidak**
"""

review_produk_df.groupby(by=["product_category_name_english"]).agg({
    "review_id": "nunique",
    "review_score": ["max", "min", "mean", "std"]
})

"""**Insight :**

terlihat dari data di atas, yang banyak menerima review adalah kategori produk ""Watches Gifts" dengan jumlah ulasan sebanyak 5.582. rata-rata kategori produk mendapat skor ulasan 5.

**Menggabungkan Dataset customer_df dan review_produk_df**

Pada tahap ini, kita akan mengeksplorasi data review_produk_df dan customer_df. Dengan menggabungkan data pelanggan dan ulasan, maka bisa mendapatkan wawasan yang lebih mendalam tentang kepuasan pelanggan. Ini termasuk analisis skor ulasan berdasarkan lokasi geografis pelanggan.
"""

review_produk_cust_df = pd.merge(customer_df, review_produk_df, on='customer_id')

"""rangkuman parameter statistik dari review_produk_cust_df :"""

review_produk_cust_df.describe(include="all")

"""**Insight :**

1. Pelanggan tersebar di berbagai kota dan negara bagian. Kota dengan jumlah pelanggan terbanyak adalah Sao Paulo, dengan 17,793 pelanggan, dan negara bagian dengan jumlah pelanggan terbanyak adalah SP, dengan 47,387 pelanggan.
2. Skor ulasan bervariasi dari 1 hingga 5, dengan rata-rata skor ulasan sekitar 4.03. Sebagian besar ulasan cenderung positif, yang mencerminkan kepuasan pelanggan yang tinggi.
3. Kategori dengan jumlah produk terbanyak adalah bed_bath_table dengan 12,735 produk.
4. Terdapat 3,088 penjual. Kota dengan jumlah penjual terbanyak adalah Sao Paulo (20,020 penjual) dan negara bagian dengan jumlah penjual terbanyak adalah SP (80,318 penjual)

**Berikut informasi yang bisa didapat dari data di atas :**

- **Distribusi Ulasan Berdasarkan Kota Pelanggan dan Skor Ulasan.**
"""

review_produk_cust_df.groupby(by=["review_score", "customer_city"]).agg({
    "review_id": "nunique",
    "customer_id": "nunique",
    "product_id": "nunique",
})

"""**Insight :**

1. Setiap produk hanya memiliki satu ulasan. Dalam hal ini, setiap review_id untuk setiap product_id, sehingga jumlahnya sama.
2. Ini juga menunjukkan bahwa beberapa kota memiliki jumlah ulasan yang lebih tinggi dengan skor tertentu, yang bisa menjadi indikasi kepuasan atau ketidakpuasan pelanggan di kota tersebut.

**Menggabungkan Dataset seller_df dan review_produk_df**

Pada tahap ini, kita akan mengeksplorasi data review_produk_df dan seller_df. Dengan menggabungkan data penjual dan ulasan, maka memungkinkan untuk melakukan segmentasi penjual berdasarkan skor ulasan dan lokasi geografis mereka. Ini membantu dalam mengidentifikasi penjual yang paling sukses dan yang memerlukan dukungan tambahan.
"""

review_produk_seller_df = pd.merge(seller_df, review_produk_df, on='seller_id')

"""rangkuman parameter statistik dari review_produk_seller_df :"""

review_produk_seller_df.describe(include="all")

"""**Insight :**

1. Dataset ini mencakup 3,088 penjual.
2. Penjual tersebar di berbagai kota dan negara bagian. Kota dengan jumlah penjual terbanyak adalah Sao Paulo, dengan 27,855 penjual, dan negara bagian dengan jumlah penjual terbanyak adalah SP, dengan 80,129 penjual.
3. Skor ulasan bervariasi dari 1 hingga 5, dengan rata-rata skor ulasan sekitar 4.03. Sebagian besar ulasan cenderung positif, yang mencerminkan kepuasan pelanggan yang tinggi.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Distribusi Ulasan Berdasarkan Kota Penjual dan Skor Ulasan.**
"""

review_produk_seller_df.groupby(by=["review_score", "seller_city"]).agg({
    "review_id": "nunique",
    "seller_id": "nunique",
    "customer_id": "nunique",
    "product_id": "nunique"
})

"""**Insight :**

1. Penjual yang mendapat skor ulasan 1 samapi 5 tersebar di beberapa kota.
2. Perbedaan jumlah ini mencerminkan variasi dalam data ulasan, penjual, pelanggan, dan produk yang diulas.
3. Jumlah review_id menunjukkan jumlah total ulasan yang diberikan oleh pelanggan.
4. Satu produk bisa menerima beberapa ulasan dari pelanggan yang berbeda. Oleh karena itu, jumlah product_id bisa lebih kecil dibandingkan jumlah review_id jika satu produk menerima banyak ulasan.
5. Satu penjual bisa menjual beberapa produk dan menerima beberapa ulasan dari pelanggan yang berbeda. Oleh karena itu, jumlah seller_id bisa lebih kecil dibandingkan jumlah review_id jika satu penjual menerima banyak ulasan
6. Seorang pelanggan bisa memberikan beberapa ulasan untuk produk yang berbeda atau bahkan untuk produk yang sama. Oleh karena itu, jumlah customer_id bisa lebih kecil dibandingkan jumlah review_id jika satu pelanggan memberikan banyak ulasan.
7. Contoh misalkan pada penjual yang berasal dari kota volta redonda ada 78 ulasan (review_id) untuk 22 produk (product_id) yang dijual oleh 2 penjual (seller_id) dan diberikan ulasan oleh 78 pelanggan (customer_id).

**Eksplorasi Data payment_df**
"""

payment_df.describe(include="all")

"""**Insight :**

1. Dataset ini mencakup 103,886 pesanan
2. Metode pembayaran yang paling sering digunakan adalah kartu kredit, dengan 76,795 transaksi menggunakan kartu kredit.
3. Ada 5 metode pembayaran yang digunakan dalam dataset ini.
4. Rata-rata urutan pembayaran adalah sekitar 1.09, dengan standar deviasi 0.71. Ini menunjukkan bahwa sebagian besar pesanan dilakukan dalam satu kali pembayaran.
5. Rata-rata jumlah cicilan adalah sekitar 2.85, dengan standar deviasi 2.69. Ini menunjukkan bahwa sebagian besar pesanan dilakukan dalam beberapa cicilan.
6. Jumlah cicilan maksimum adalah 24, menunjukkan bahwa ada pesanan yang dilakukan dalam banyak cicilan.
7. Rata-rata nilai pembayaran adalah sekitar 154.10, dengan standar deviasi 217.49. Ini menunjukkan bahwa nilai pembayaran bervariasi secara signifikan.
8. Nilai pembayaran maksimum adalah 13,664.08, menunjukkan bahwa ada pesanan dengan nilai pembayaran yang sangat tinggi.
9. Nilai pembayaran minimum adalah 0, menunjukkan bahwa ada pesanan dengan nilai pembayaran yang sangat rendah atau bahkan gratis.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Metode pembayaran yang paling populer di kalangan pelanggan.**
"""

payment_df.groupby(by="payment_type").order_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

Kartu kredit adalah metode pembayaran yang paling populer di kalangan pelanggan, dengan jumlah pesanan yang jauh lebih tinggi dibandingkan metode pembayaran lainnya.

- **Metode pembayaran yang paling signifikan dalam hal nilai transaksi.**
"""

payment_df.groupby(by="payment_type").payment_value.sum().sort_values(ascending=False).reset_index()

"""**Insight :**

Kartu kredit adalah metode pembayaran yang memberikan kontribusi terbesar terhadap total nilai pembayaran. Ini menunjukkan bahwa pelanggan cenderung menggunakan kartu kredit untuk transaksi dengan nilai yang lebih tinggi.

**Menggabungkan Dataset payment_df dan order_produk_baru_df**

Pada tahap ini, kita akan mengeksplorasi data payment_df dan order_produk_baru_df. Kita bisa menganalisis hubungan antara produk yang dipesan dan metode pembayaran yang digunakan.
"""

payment_produk_df = pd.merge(payment_df, order_produk_baru_df, on='order_id')

"""rangkuman parameter statistik dari payment_produk_df :"""

payment_produk_df.describe(include="all")

"""**Insight :**

1. Dataset ini mencakup 98,644 pesanan
2. Terdapat 4 metode pembayaran yang digunakan oleh pelanggan. Metode pembayaran yang paling sering digunakan adalah kartu kredit, dengan 86,756 transaksi.
3. Rata-rata nilai pembayaran adalah sekitar 172.67, dengan standar deviasi 267.58. Nilai pembayaran bervariasi secara signifikan, dengan nilai pembayaran maksimum mencapai 13,664.08.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Metode pembayaran yang paling populer di kalangan pelanggan.**
"""

payment_produk_df.groupby(by="payment_type").customer_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

Kartu kredit adalah metode pembayaran yang paling populer di kalangan pelanggan, dengan jumlah pelanggan yang jauh lebih tinggi dibandingkan metode pembayaran lainnya.

- **Metode pembayaran yang paling populer untuk produk.**
"""

payment_produk_df.groupby(by="payment_type").product_id.nunique().sort_values(ascending=False).reset_index()

"""**Insight :**

Kartu kredit adalah metode pembayaran yang paling sering digunakan oleh pelanggan untuk membeli produk, dengan jumlah produk yang jauh lebih tinggi dibandingkan metode pembayaran lainnya.

- **Distribusi Pesanan Berdasarkan Jenis Pembayaran dan Kategori Produk.**
"""

payment_produk_df.groupby(by=["payment_type", "product_category_name_english"]).agg({
    "order_id": "nunique",
    "payment_value": ["max", "min", "mean", "std"]
})

"""**Insight :**

Berdasarkan jenis pembayaran dan kategori produk, nilai pembayaran cukup variatif

- **Kategori produk dengan total nilai pembayaran tertinggi.**
"""

payment_produk_df.groupby(by="product_category_name_english").payment_value.sum().sort_values(ascending=False).reset_index().head()

"""**Insight :**

Kategori bed_bath_table memiliki total nilai pembayaran tertinggi.

**Menggabungkan Dataset customer_df dan payment_produk_df**

Pada tahap ini, kita akan mengeksplorasi data customer_df dan payment_produk_df. Ini membantu dalam memahami profil pelanggan yang menggunakan metode pembayaran tertentu.
"""

payment_produk_cust_df = pd.merge(payment_produk_df, customer_df, on='customer_id')

"""rangkuman parameter statistik dari payment_produk_cust_df :"""

payment_produk_cust_df.describe(include="all")

"""**Insight :**

1. Kartu kredit adalah metode pembayaran yang paling sering digunakan oleh pelanggan, dengan 86,756 transaksi.
2. Pelanggan tersebar di berbagai kota dan negara bagian. Kota dengan jumlah pelanggan terbanyak adalah Sao Paulo, dengan 18,589 pelanggan, dan negara bagian dengan jumlah pelanggan terbanyak adalah SP, dengan 49,554 pelanggan.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Distribusi Pesanan Berdasarkan Jenis Pembayaran dan Kota Pelanggan.**
"""

payment_produk_cust_df.groupby(by=["payment_type", "customer_city"]).agg({
    "order_id": "nunique",
})

"""**Insight :**

Pesanan yang menggunakan berbagai metode pembayaran (seperti kartu kredit, boleto, voucher, dan kartu debit) didistribusikan secara relatif seimbang di berbagai kota. Ini menunjukkan bahwa tidak ada satu metode pembayaran yang mendominasi di kota tertentu, melainkan semua metode pembayaran digunakan oleh pelanggan di berbagai lokasi geografis.

- **Distribusi Pesanan Berdasarkan Jenis Pembayaran dan Negara Pelanggan.**
"""

payment_produk_cust_df.groupby(by=["payment_type", "customer_state"]).agg({
    "order_id": "nunique",
})

"""**Insight :**

Pesanan yang menggunakan berbagai metode pembayaran (seperti kartu kredit, boleto, voucher, dan kartu debit) didistribusikan secara merata di berbagai negara. Namun ada tipe pembayaran yang mendominasi di beberapa negara. Metode Pembayaran Boleto, Terdapat 608 pesanan menggunakan boleto, menunjukkan bahwa metode ini cukup populer di negara bagian BA. Metode Pembayaran Voucher, Terdapat 1,551 pesanan unik menggunakan voucher, menunjukkan bahwa metode ini cukup populer di negara bagian SP.

- **Negara bagian dengan total nilai pembayaran tertinggi.**
"""

payment_produk_cust_df.groupby(by="customer_state").payment_value.sum().sort_values(ascending=False).reset_index().head()

"""**Insight :**

Negara SP memiliki total nilai pembayaran tertinggi.

- **Kota pelanggan dengan total nilai pembayaran tertinggi.**
"""

payment_produk_cust_df.groupby(by="customer_city").payment_value.sum().sort_values(ascending=False).reset_index().head()

"""**Insight :**

Kota sao paulo ini memiliki total nilai pembayaran tertinggi.

**Menggabungkan Dataset seller_df dan payment_produk_df**

Pada tahap ini, kita akan mengeksplorasi data seller_df dan payment_produk_df. Ini membantu dalam memahami profil penjual dengan metode pembayaran tertentu.
"""

payment_produk_seller_df = pd.merge(payment_produk_df, seller_df, on='seller_id')

"""rangkuman parameter statistik dari payment_produk_seller_df :"""

payment_produk_seller_df.describe(include="all")

"""**Insight :**

1. Kartu kredit adalah metode pembayaran yang paling sering digunakan, dengan 86,756 transaksi.
2. Penjual tersebar di berbagai kota dan negara bagian. Kota dengan jumlah penjual terbanyak adalah Sao Paulo, dengan 29,149 penjual, dan negara bagian dengan jumlah penjual terbanyak adalah SP, dengan 83,829 penjual.

**Berikut informasi yang bisa didapat dari data di atas :**

- **Distribusi Pesanan Berdasarkan Jenis Pembayaran dan Kota Penjual.**
"""

payment_produk_seller_df.groupby(by=["payment_type", "seller_city"]).agg({
    "order_id": "nunique",
})

"""**Insight :**

Pesanan yang menggunakan berbagai metode pembayaran (seperti kartu kredit, boleto, voucher, dan kartu debit) didistribusikan secara merata di berbagai kota penjual. Namun ada tipe pembayaran yang mendominasi di beberapa kota. Metode Pembayaran Boleto, Terdapat 22 pesanan menggunakan boleto, menunjukkan bahwa metode ini cukup populer di kota tersebut.

- **Distribusi Pesanan Berdasarkan Jenis Pembayaran dan Negara Penjual.**
"""

payment_produk_seller_df.groupby(by=["payment_type", "seller_state"]).agg({
    "order_id": "nunique",
})

"""**Insight :**

Pesanan yang menggunakan berbagai metode pembayaran (seperti kartu kredit, boleto, voucher, dan kartu debit) didistribusikan secara merata di berbagai negara penjual. Namun ada tipe pembayaran yang mendominasi di beberapa kota. Metode Pembayaran voucher, Terdapat 2769 pesanan menggunakan pembayaran voucher, menunjukkan bahwa metode ini cukup populer di kota tersebut.

- **Kota penjual dengan total nilai pembayaran tertinggi.**
"""

payment_produk_seller_df.groupby(by="seller_city").payment_value.sum().sort_values(ascending=False).reset_index().head()

"""**Insight :**

São Paulo memiliki total nilai pembayaran tertinggi, menunjukkan bahwa kota ini merupakan pusat aktivitas penjualan yang signifikan.

- **Negara penjual dengan total nilai pembayaran tertinggi.**
"""

payment_produk_seller_df.groupby(by="seller_state").payment_value.sum().sort_values(ascending=False).reset_index().head()

"""**Insight :**

SP memiliki total nilai pembayaran tertinggi, menunjukkan bahwa negara bagian ini merupakan pusat aktivitas penjualan yang sangat signifikan.

**Eksplorasi Data all_df**

Pada tahap ini, kita akan menggabungkan dataset-dataset yang kita punya untuk membuat dataFrame baru bernama **all_df** dimana menampung informasi dari tabel-tabel yang kita miliki. Selain itu dataframe yang dibuat ini akan digunakan nantinya untuk membuat dashboard di streamlit.

Proses penggabungan dataset ini akan melalui beberapa tahap dikarenakan jumlah dataset yang banyak. Namun untuk menghemat tahapan, kita akan mulai dari menggabungkan dataset **order_produk_baru_cust_df** dengan dataset **review_df** dimana dataset **order_produk_baru_cust_df** sendiri merupakan gabungan dari 5 dataset sebelumnya yaitu orders_df, order_item_df, produk_df, kategori_produk_df dan customer_df.

Berikut tahapan dalam proses penggabungan dataset ini.

**Tahap 1 : Menggabungkan dataset order_produk_baru_cust_df dan review_df**
"""

merged_1_df = pd.merge(
    left=order_produk_baru_cust_df,
    right=review_df,
    how="left",
    left_on="order_id",
    right_on="order_id"
)

"""**Tahap 2 : Menggabungkan dataset merged_1_df dan payment_df**"""

merged_2_df = pd.merge(
    left=merged_1_df,
    right=payment_df,
    how="left",
    left_on="order_id",
    right_on="order_id"
)

"""**Tahap 3 : Menggabungkan dataset merged_2_df dan seller_df**"""

all_df = pd.merge(
    left=merged_2_df,
    right=seller_df,
    how="left",
    left_on="seller_id",
    right_on="seller_id"
)

"""**Menyiapkan DataFrame yang akan digunakan untuk membuat dashboard dengan Streamlit**"""

import os

# Menentukan path untuk menyimpan file
subdir = 'dashboard'
filename = 'all_data_ecommerce.csv'
file_path = os.path.join(subdir, filename)

# Menyimpan DataFrame ke file .csv
all_df.to_csv(file_path, index=False)

"""### Visualization & Explanatory Analysis

**Pertanyaan 1 : Produk apa yang paling banyak dan paling sedikit terjual ?**
"""

# Membuat dua buah visualisasi dalam satu gambar
fig, axes = plt.subplots(1, 2, figsize=(7, 6))

# Hitung jumlah penjualan untuk setiap produk
produk_terjual = all_df.groupby('product_category_name_english').size().reset_index(name='count')

# Urutkan berdasarkan jumlah penjualan
produk_terjual = produk_terjual.sort_values(by='count', ascending=False)

# Visualisasi produk yang paling banyak terjual
sns.barplot(x='product_category_name_english', y='count', data=produk_terjual.head(), ax=axes[0], palette='viridis')
axes[0].set_title('Produk yang Paling Banyak Terjual')
axes[0].set_xlabel('Kategori Produk')
axes[0].tick_params(axis='x', rotation=90)
axes[0].set_ylabel('Jumlah Penjualan')

# Visualisasi produk yang paling sedikit terjual
sns.barplot(x='product_category_name_english', y='count', data=produk_terjual.tail(), ax=axes[1], palette='viridis')
axes[1].set_title('Produk yang Paling Sedikit Terjual')
axes[1].set_xlabel('Kategori Produk')
axes[1].tick_params(axis='x', rotation=90)
axes[1].set_ylabel('Jumlah Penjualan')

plt.tight_layout()
plt.show()

# Menampilkan data
print(produk_terjual.head())
print(produk_terjual.tail())

"""**Insight :**

1. Visualisasi ini menunjukkan kategori produk **bed_bath_table muncul sebagai kategori dengan penjualan tertinggi**, ini menunjukkan bahwa produk-produk dalam kategori ini sangat populer dan memiliki permintaan yang tinggi.
2. Sedangkan kategori **security_and_services muncul sebagai kategori dengan penjualan terendah**, ini menunjukkan bahwa produk-produk dalam kategori ini kurang populer dan memiliki permintaan yang rendah.

**Pertanyaan 2 : Berapa banyak revenue yang didapat dalam 6 bulan terakhir dan sepanjang periode ?**

**2.1. Revenue yang didapat dalam 6 bulan terakhir**
"""

# Tentukan tanggal maksimal dan hitung tanggal 6 bulan sebelumnya
tanggal_maksimal = all_df['order_purchase_timestamp'].max()
tanggal_6_bulan_sebelumnya = tanggal_maksimal - pd.DateOffset(months=6)

# Filter data untuk 6 bulan terakhir
recent_payments = all_df[all_df['order_purchase_timestamp'] >= tanggal_6_bulan_sebelumnya]

# Hitung total uang yang dihabiskan pelanggan berdasarkan bulan
total_spent_per_month = recent_payments.groupby(recent_payments['order_purchase_timestamp'].dt.to_period('M'))['payment_value'].sum().reset_index()
print(total_spent_per_month)

# Buat visualisasi
plt.figure(figsize=(8, 4))
sns.barplot(x='order_purchase_timestamp', y='payment_value', data=total_spent_per_month, palette='viridis')
plt.title('Revenue yang didapat dalam 6 bulan terakhir')
plt.xlabel('Periode (Bulan dan Tahun)')
plt.ylabel('Total Payment')
plt.xticks(rotation=0)
plt.show()

"""**Insight :**

Dari visualisasi tersebut, kita bisa menyimpulkan bahwa pada bulan **Mei 2018**, total uang yang dihabiskan oleh pelanggan mencapai puncaknya dibandingkan dengan bulan-bulan lainnya dalam periode 6 bulan terakhir. Kemungkinan alasan untuk peningkatan ini bisa dikeranakan adanya promosi/diskon, musim liburan, atau adanya peluncuran produk baru.

**2.2. Revenue yang didapat sepanjang periode**
"""

# Pastikan kolom tanggal dalam format datetime
all_df['order_purchase_timestamp'] = pd.to_datetime(all_df['order_purchase_timestamp'])

# Konversi menjadi periode bulan dan tahun
all_df['order_purchase_period'] = all_df['order_purchase_timestamp'].dt.to_period('M')

# Hitung total uang yang dihabiskan pelanggan berdasarkan periode
total_spent_per_period = all_df.groupby('order_purchase_period')['payment_value'].sum().reset_index()
print(total_spent_per_period)

# Buat visualisasi barplot
plt.figure(figsize=(8, 6))
sns.barplot(x='payment_value', y='order_purchase_period', data=total_spent_per_period, palette='viridis')
plt.title('Revenue yang didapat sepanjang periode')
plt.xlabel('Total Payment')
plt.ylabel('Periode (Bulan dan Tahun')
plt.xticks(rotation=0)
plt.show()

"""**Insight :**

1. Terdapat fluktuasi pendapatan yang signifikan sepanjang periode. Misalnya, pengeluaran pada **bulan November 2017 adalah 1,595,006.04**, yang kemudian **menurun pada bulan Desember 2017 menjadi 1,046,223.15**. Fluktuasi ini bisa disebabkan oleh berbagai faktor, termasuk musim liburan atau perubahan dalam strategi pemasaran.
2. Bulan dengan **pendapatan tertinggi adalah November 2017, dengan total pendapatan 1,595,006.04**. Ini menunjukkan bahwa ada faktor-faktor tertentu yang mendorong peningkatan belanja pada bulan tersebut, seperti promosi, diskon, atau acara khusus.
3. Bulan dengan **pendapatan terendah adalah Desember 2016, dengan total pendapatan hanya 19.62**. Ini mungkin menunjukkan bahwa ada faktor lain yang menyebabkan rendahnya pendapatan pada bulan tersebut.

### Teknik Analisis Lanjutan

**RFM Analysis (Recency, Frequency, Monetary)**

- **Distribution of Recency, Frequency, Monetary**
"""

# Pastikan kolom tanggal dalam format datetime
all_df['order_purchase_timestamp'] = pd.to_datetime(all_df['order_purchase_timestamp'])

# Hitung nilai Recency, Frequency, dan Monetary
current_date = all_df['order_purchase_timestamp'].max()
all_df['order_purchase_timestamp'] = pd.to_datetime(all_df['order_purchase_timestamp'])

rfm_df = all_df.groupby('customer_id').agg({
    'order_purchase_timestamp': lambda x: (current_date - x.max()).days,
    'order_id': 'count',
    'payment_value': 'sum'
}).reset_index()

rfm_df.columns = ['customer_id', 'Recency', 'Frequency', 'Monetary']

# Visualisasi Recency, Frequency, dan Monetary
fig, axes = plt.subplots(1, 3, figsize=(16, 5))

# Visualisasi Recency
sns.histplot(rfm_df['Recency'], bins=20, kde=True, ax=axes[0])
axes[0].set_title('Distribution of Recency')
axes[0].set_xlabel('Recency (days)')
axes[0].set_ylabel('Frequency')

# Visualisasi Frequency
sns.histplot(rfm_df['Frequency'], bins=20, kde=True, ax=axes[1])
axes[1].set_title('Distribution of Frequency')
axes[1].set_xlabel('Frequency (orders)')
axes[1].set_ylabel('Frequency')

# Visualisasi Monetary
sns.histplot(rfm_df['Monetary'], bins=20, kde=True, ax=axes[2])
axes[2].set_title('Distribution of Monetary')
axes[2].set_xlabel('Monetary ($)')
axes[2].set_ylabel('Frequency')

plt.tight_layout()
plt.show()

"""- **Average Recency, Frequency, and Monetary Values**"""

# Hitung rata-rata Recency, Frequency, dan Monetary
average_recency = round(rfm_df['Recency'].mean(), 2)
average_frequency = round(rfm_df['Frequency'].mean(), 2)
average_monetary = round(rfm_df['Monetary'].mean(), 2)

# Tampilkan hasil
print(f"Average Recency: {average_recency} days")
print(f"Average Frequency: {average_frequency} orders")
print(f"Average Monetary: ${average_monetary:,.2f}")

# Visualisasi nilai rata-rata Recency, Frequency, dan Monetary
average_values = pd.DataFrame({
    'Metric': ['Recency', 'Frequency', 'Monetary'],
    'Average Value': [average_recency, average_frequency, average_monetary]
})

plt.figure(figsize=(5, 4))
sns.barplot(x='Metric', y='Average Value', data=average_values, palette='viridis')
plt.title('Average Recency, Frequency, and Monetary Values')
plt.xlabel('Metric')
plt.ylabel('Average Value')
plt.show()

"""**Clustering**

- **Metode Manual Grouping : kategori pelanggan berdasarkan rentang nilai Monetary**
"""

# Contoh data RFM
data = {
    'customer_id': range(1, 101),
    'Recency': [i % 30 for i in range(1, 101)],
    'Frequency': [i % 10 for i in range(1, 101)],
    'Monetary': [i * 100 for i in range(1, 101)]
}

rfm_df = pd.DataFrame(data)

# Manual Grouping berdasarkan nilai Monetary
def manual_grouping(monetary):
    if monetary < 1000:
        return 'Low'
    elif 1000 <= monetary < 5000:
        return 'Medium'
    else:
        return 'High'

rfm_df['Monetary_Group'] = rfm_df['Monetary'].apply(manual_grouping)

# Visualisasi Manual Grouping
plt.figure(figsize=(5, 3))
sns.countplot(x='Monetary_Group', data=rfm_df, palette='viridis')
plt.title('Kategori pelanggan berdasarkan nilai Monetary')
plt.xlabel('Monetary Group')
plt.ylabel('Jumlah Customers')
plt.show()

"""- **Metode Binning : membagi nilai Recency ke dalam beberapa interval/kategori.**"""

# Binning berdasarkan nilai Recency
bins = [0, 10, 20, 30]
labels = ['0-10 days', '11-20 days', '21-30 days']
rfm_df['Recency_Bin'] = pd.cut(rfm_df['Recency'], bins=bins, labels=labels, right=False)

# Visualisasi Binning
plt.figure(figsize=(5, 3))
sns.countplot(x='Recency_Bin', data=rfm_df, palette='viridis')
plt.title('Kategori pelanggan base on waktu interval pembelian')
plt.xlabel('Interval pembelian')
plt.ylabel('Jumlah Customers')
plt.show()

"""### Conclusion

**Conclution pertanyaan 1 : Produk apa yang paling banyak dan paling sedikit terjual ?**

**1. Produk dengan Penjualan Tertinggi**


a. Kategori Produk: Produk dalam kategori bed_bath_table memiliki jumlah penjualan tertinggi.


b. Jumlah Penjualan: Total penjualan dalam kategori ini mencapai 13.521 produk.


c. Insight: Tingginya permintaan terhadap produk dalam kategori ini menunjukkan popularitasnya di kalangan pelanggan. Hal ini dapat menjadi fokus utama dalam strategi pemasaran dan manajemen stok untuk memastikan ketersediaan produk yang diminati.



**2. Produk dengan Penjualan Terendah**

a. Kategori Produk: Produk dalam kategori security_and_services memiliki jumlah penjualan terendah.


b. Jumlah Penjualan: Hanya 2 produk dalam kategori ini yang terjual.


c. Insight: Rendahnya permintaan terhadap produk dalam kategori ini menunjukkan kurangnya minat pelanggan. Evaluasi lebih lanjut diperlukan untuk menentukan apakah produk ini perlu diperbaiki, dihapus, atau diganti dengan yang lebih diminati. Strategi promosi atau diskon khusus juga bisa dipertimbangkan untuk meningkatkan penjualan.

**Conclution pertanyaan 2 : Berapa banyak revenue yang didapat dalam 6 bulan terakhir dan sepanjang periode ?**

**1. Revenue yang didapat dalam 6 bulan terakhir :**

**Periode :** Maret 2018 hingga September 2018.

**Insight :** Pengeluaran pelanggan mencapai puncaknya pada bulan Mei 2018 dengan total pengeluaran sebesar Rp 1,504,928.43. Ini menunjukkan bahwa ada faktor-faktor tertentu yang mendorong peningkatan belanja pada bulan tersebut, seperti promosi, diskon, atau acara khusus. Pengeluaran pelanggan pada bulan September 2018 sangat rendah, hanya sebesar Rp 166.46. Ini mungkin menunjukkan bahwa ada faktor-faktor tertentu yang menyebabkan penurunan drastis dalam pengeluaran.

**2. Revenue yang didapat sepanjang periode :**

**Periode :** September 2016 hingga September 2018.

**Insight :** Pengeluaran pelanggan menunjukkan tren peningkatan yang konsisten dari waktu ke waktu, dengan beberapa fluktuasi. Puncak pengeluaran terjadi pada bulan November 2017 sebesar Rp 1,583,869.01 dan pada bulan Mei 2018 sebesar Rp 1,504,928.43. Fluktuasi ini bisa disebabkan oleh berbagai faktor, termasuk musim liburan, promosi, atau perubahan dalam strategi pemasaran.
"""

